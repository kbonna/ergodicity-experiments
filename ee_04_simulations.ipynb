{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd69f28-2f97-45f2-81d3-6101f7848c96",
   "metadata": {},
   "source": [
    "# Simulations\n",
    "\n",
    "This notebook contains the code to generate ergodicity experiment simulations. Basic idea behind these simulations is that we want to **find optimal experimental design maximizing the disagreement between competing theories**. Here, we are able to simulate different isoelastic agents facing different wealth dynamics. According to ergodicity economics, time-optimal agent should use an isoelastic utility function with risk parameter equal to risk parameter generating wealth dynamics, to maximize growth of its wealth over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations, combinations_with_replacement, product\n",
    "from utils.plotting import aligned_imshow_cbar\n",
    "from utils.paralell import (agent_name, calculate_beta, isoelastic_utility, \n",
    "                            inverse_isoelastic_utility, wealth_change, \n",
    "                            shuffle_along_axis, create_gambles, \n",
    "                            create_gamble_pairs, create_trial_order, \n",
    "                            create_experiment, is_mixed, is_nobrainer, \n",
    "                            is_equal_growth, disagreement, bankruptcy_chance, \n",
    "                            richness_chance, experiment_duration, \n",
    "                            run_simulation, softmax, create_dmag_thrs, \n",
    "                            create_mag_thrs, create_var_thrs, \n",
    "                            is_g_deterministic)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-juvenile",
   "metadata": {},
   "source": [
    "## Modeling the agent\n",
    "\n",
    "Assumptions about the agent:\n",
    "1. Agent perfectly knows how different wealth changes influence his current wealth.\n",
    "    - In real experiment this assumption is realized during the passive session in which subjects learn how different wealth changes influence dynamics. Obviously, real participant cannot perfectly know the effect of wealth change, but they can approximate it well enough to make appropriate choices during the active phase.\n",
    "2. Agent tracks his current wealth after each trial.\n",
    "    - This assumption may not be met if the improved experiment would not involve visible wealths (as original Copenhagen experiment). It is still a matter of debate how hidden wealth should be treated. There are two possible solutions. First, we can assume that agents calculate their choices as if they are constantly endowed with inital wealth $x_0$. On the other hand, choosing the gambles give (at least theoretically) access to possible wealth trajectories. However, after just a few trials the space of possible trajectories becomes to vast to computationally track. Experiment with hidden wealth assuming constant wealth level is very easy to optimize, because it lacs *wealth-trajectory-dependent* effects on choice. Inspection of $\\eta^*$ plots lead to the observation that choice preference depends on agent's wealth for all dynamics other than multiplicative.    \n",
    "3. At each trial agent is facing two gambles and it has to choose one of them.\n",
    "4. Agent is computing expected change in utility for both gambles to guide his choice.\n",
    "    - This is essential part of the behavioral model. Let's assume that agent is facing a pair of gambles: $g_a=(\\gamma^a_1, \\gamma^a_2)$, and $g_b=(\\gamma^b_1, \\gamma^b_2)$. Lets also assume that agent's risk attitude is $\\eta_{\\text{agent}}$ and the wealth dynamics is given by $\\eta_{\\text{dynamic}}$. Lets denote agent's utility function (the Isoelastic utility with $\\eta=\\eta_{\\text{agent}}$) as $u$, and time-optimal utility function (the Isoelastic utility with $\\eta=\\eta_{\\text{dynamict}}$) as $u^*$. An agent first computes utility of his current wealth $u(x_t)$. Then, for each gamble he calculates expected utility for this gamble as:\n",
    "    $$E[u^{a/b}(x_{t+1})]=\\frac{1}{2}(u(u_*^{-1}(u_*(x_t)+\\gamma^{a/b}_1))+u(u_*^{-1}(u_*(x_t)+\\gamma^{a/b}_2))).$$\n",
    "Then, the agent computes expected change in utility for $g_a$ and $g_b$ as:\n",
    "    $$E[\\Delta u^{a/b}]=E[u^{a/b}(x_{t+1})-u(x_t)]=E[u^{a/b}(x_{t+1})]-u(x_t)$$\n",
    "> Note that for the time-optimal agent $u=u_*$, so $E[u^{a/b}(x_{t+1})]=u(x_t)+\\frac{\\gamma^{a/b}_1+\\gamma^{a/b}_2}{2}$. This implies that $E[\\Delta u^{a/b}]=\\frac{\\gamma^{a/b}_1+\\gamma^{a/b}_2}{2}$, so expected change in utility for a gamble reflects true average growth rate for that gamble. \n",
    "\n",
    "5. These expected changes in utility are passed through [Softmax choice function](https://en.wikipedia.org/wiki/Softmax_function) to simulate choice stochasticity. \n",
    "    - Probability of choosing gamble $g_a$ is given as:\n",
    "    $$P(a)=\\exp^{-1}(\\beta(E[\\Delta u^a]-E[\\Delta u^b]))$$\n",
    "    - Since different agents use different utility function, softmax precision parameter $\\beta$ is normalized between agents. Normalized precision is a precision for which an agent endowed with initial wealth $x0$ and facing two extreme, opposite fractals with growth rates $-c$, and $c$ would choose the winning fractal with probability $p_{\\text{threshold}}$. Function `calculate_beta` can be used to find normalized precision for agent with risk attitude $\\eta$. Normalized precision depends on agent's risk attitude, wealth dynamic, intial wealth, growth rate scaling $c$, and probability threshold specified by the user.\n",
    "6. Softmax function return choice probabilities for both gambles that are used to generate actual choice.\n",
    "\n",
    "## Modeling an experiment\n",
    "\n",
    "Assumptions about the experiment:\n",
    "1. Each experiment consists of specified number of trials, $N_{\\text{trials}}$, contolled by the `n_trials` variable.\n",
    "2. Any number of gamble pairs can be used to generate the experiment. \n",
    "    - If the number of available gamble pairs is less than $N_{\\text{trials}}$, gamble pairs are repeated to fill the duration of the experiment. For example, constraining gamble pair space to 100 unique gamble pairs with $N_{\\text{trials}}=360$ would lead repeating each gamble pair 3 or 4 times (60 gamble pairs repeated one extra time are randomly selected). The order of gambles is random.\n",
    "    - If the number of available gamble pairs is greater than $N_{\\text{trials}}$, a random subset of $N_{\\text{trials}}$ gamble pairs is selected for each simulated run. Different runs would result in different subset, so each available gamble pair has equal change of being selected.   \n",
    "3. Available gamble pairs constituing an experiment are selected by geometrically constraining gamble and gamble pair space (see notebook `ee_03`).      \n",
    "4. Single simulated run can be prematurely terminated if agent's wealth drop below 0 or raise above $x_{\\text{limit}}$.\n",
    "    - This assumption introduces lower and upper bounds to agents wealth. This is very pragmatic as it provides simple means of controlling cost, but has some associated caveats. In particular it has been shown that time-optimal behavior changes close to the wealth bounds. Modeling this termination mechanism also benefits disagreement measure. Terminated trajectories, i.e., experiments that ended prematurely have less contribution to overall disagreement. In this way, disagreement not only quantifies our ability to discriminate agents, but also is sensible to cost problems for experiments with excessive wins or losses.\n",
    "5. For each setup comprised of fixed: gamble pair set, growth rate scaling $c$, agent risk attitude $\\eta_{\\text{agent}}$ multiple runs are simulated in parallel. We will refer to this set of simulations as to *parallel run*.\n",
    "    - Simulating multiple realizations is important because of the wealth-trajectory-dependency problem. By realizing same setup multiple times we can get more accurate approximation of true expected disagreement. Number of performed run is controlled by the `n_simulations` variable.\n",
    "  \n",
    "## Gamble space constraints\n",
    "\n",
    "Additional assumptions about constraining gamble space (specific to the second version of the simulation):\n",
    "1. $\\gamma_{\\text{min}}$ and $\\gamma_{\\text{max}}$ are included but only first seven bound positions are considered. The seventh position corresponds to the setup for which all but one win-only or loss-only gambles are removed. This limitation is imposed to prevent excessive imbalance between win-only and loss-only gambles.\n",
    "2. $var_{\\text{min}}$ and $var_{\\text{min}}$ are excluded but the setting for $var_{\\text{min}}$ is fixed to 1, i.e. first possible bound placement excluding all deterministic gambles. Deterministic gambles are excluded to prevent imbalances resulting from subject's aversion/liking towards gambling. \n",
    "3. $\\Delta \\gamma_{\\text{max}}$ is included with all possible levels, but $\\Delta \\gamma_{\\text{min}}$ is excluded. Since $\\eta^*$ plots showed that discrepant trials are often comprised of two gambles with similar average growth rates, it is more important to remove gamble pairs with high $\\Delta \\gamma$. \n",
    "4. $\\Delta var_{\\text{min}}$ and $\\Delta var_{\\text{max}}$ are excluded.\n",
    "> In future simulations it might be worth to include $\\Delta var_{\\text{min}}$, since $\\eta^*$ plots showed that discrepant trials are often comprised of two gambles with diffent variance.\n",
    "5. No-brainer gamble pairs are excluded.\n",
    "6. Range of growth rate scaling depends on dynamic.\n",
    "    - For risk-seeking dynamic $c$ ranges from 1 to 300000 (step 3000).\n",
    "    - For additive dynamic $c$ ranges from 1 to 300 (step 3).\n",
    "    - For risk-seeking dynamic $c$ ranges from 0.01 to 0.3 (step 0.003).\n",
    "  \n",
    "## Collected statistics\n",
    "\n",
    "After each parallel run, several statistics are collected and stored for further analysis. Individual choices and wealth trajectories are then discarded to free space for another simulation. Collected statistics:\n",
    "- `d_p`: *Softmax disagreement*. It is calculated for every pair of simulated agents. It reflects average difference in choice frequency for two Isoelastic agents.\n",
    "- `d_y`: *Choice disagreement*. It reflects the proportion of trials for which two agents selected different gambles. However, this is less useful than `d_p` because `d_y` generally have two sources: one reflecting pure randomness and the other reflecting true difference in choice preference. To better understand that imagine both agents having equal choice probability for both options. In this case they would still select different option in 50% times just because of pure randomness. Notice that this situation is useless from the perspective of discriminating competing models. \n",
    "- `p_bank`: *Bankruptcy probability*. Proportion of wealth trajectories that ended before the last planned trial because of agent's bankruptcy. It is calculated for every simulated agent independently.\n",
    "- `p_rich`: *Richness probability*. Proportion of wealth trajectories that ended before the last planned trial because of agent exceeded the upper wealth limit.\n",
    "- `avg_len`: *Expected duration of the experiment*. Average lenght of trajectory. If its equal to $N_{\\text{trials}}$, then all ended as planned. \n",
    "- `n_gamble_pairs`: *Number of unique gamble pairs*. Number of available gamble pairs (trials) for a particular experimental setup. It only depends on geometrical constraints acting on gamble and gamble pair space.\n",
    "\n",
    "## Simulation settings\n",
    "- `x_0`: Initial endowment.\n",
    "- `x_limit`: Upper wealth limit used to terminate runs that exceeded that limit. \n",
    "- `n_fractals`: Number of distinct wealth changes (fractals).\n",
    "- `n_trials`: Total number of experimental trials.\n",
    "- `p_threshold`: Critial choice probaiblity used to normalize softmax sensitivity across agents. Normalization ensures that all isoelastic agents would choose the best fractal over the worst fractal with `p_threshold` probability. Values closer to one indicate more sensitive agents and more deterministic choices.\n",
    "- `agents`: List of simulated agents. Values correspond to agent's risk attitude.\n",
    "- `eta_dynamic`: Risk attitude constituing wealth dynamic. \n",
    "- `c_min`: Minimum growth rate scaling. It should be adjusted for each dynamic separately.\n",
    "- `c_max`: Maximum growth rate scaling. It should be adjusted for each dynamic separately.\n",
    "- `n_c`: Number of samples within growth scaling range $[c_{\\text{min}}, c_{\\text{max}}]$.\n",
    "- `min_unique_gambles`: Required number of unique gamble pairs to construct the experiment. All setups with number of unique gamble pairs less than specified would not be evaluated.\n",
    "- `max_mag_n`: Maximum setting for upper and lower average growth rate bounds. Ensure that setup is not too imbalance toward winning or loosing gambles. \n",
    "- `n_simulations`: Number of individual runs performed within single parallel run.\n",
    "- `wealth_dependency`: Decision if wealth dependency effects should be taken into account. Setting this flag to `False` is appropriate for simulating experiment with hidden wealth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 1000\n",
    "x_limit = 4000\n",
    "n_fractals = 9\n",
    "n_trials = 360\n",
    "p_threshold = 0.9999\n",
    "agents = [-1, 0, 1]\n",
    "\n",
    "# Gamble space settings \n",
    "eta_dynamic = 1\n",
    "c_min = 0.001\n",
    "c_max = 0.3\n",
    "n_c = 100\n",
    "min_unique_gambles = int(360 / 4)\n",
    "max_mag_n = 7 \n",
    "\n",
    "# Other\n",
    "n_simulations = 1000\n",
    "wealth_dependency = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ef06a-c39d-47c9-a968-7457e02f358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mag_thrs = max_mag_n + 1\n",
    "n_dmag_thrs = 2 * n_fractals - 2\n",
    "\n",
    "# Store number of gambles after filtering\n",
    "n_pairs = np.zeros((n_mag_thrs, n_mag_thrs, n_dmag_thrs), dtype=int)\n",
    "\n",
    "mag_thrs = create_mag_thrs(1, n_fractals)\n",
    "dmag_thrs = create_dmag_thrs(1, n_fractals)\n",
    "for ml_idx, mh_idx in product(range(n_mag_thrs), repeat=2):\n",
    "    for md_idx in range(n_dmag_thrs):\n",
    "        \n",
    "        ml_bound = mag_thrs[ml_idx]\n",
    "        mh_bound = mag_thrs[-1 - mh_idx]\n",
    "        md_bound = dmag_thrs[md_idx]\n",
    "\n",
    "        gambles = create_gambles(1, n_fractals)\n",
    "        gambles = [\n",
    "            g for g in gambles \n",
    "            if np.mean(g) > ml_bound\n",
    "            and np.mean(g) < mh_bound\n",
    "            and not is_g_deterministic(g)\n",
    "        ]\n",
    "        \n",
    "        gamble_pairs = create_gamble_pairs(gambles)\n",
    "        gamble_pairs = [\n",
    "            gp for gp in gamble_pairs\n",
    "            if np.abs(np.mean(gp[0]) - np.mean(gp[1])) < md_bound\n",
    "            if not is_nobrainer(gp)\n",
    "        ]\n",
    "        \n",
    "        n_pairs[ml_idx, mh_idx, md_idx] = len(gamble_pairs)\n",
    "    \n",
    "    # remove redundant search values\n",
    "    cutoff = np.where(np.diff(n_pairs[ml_idx, mh_idx]) == 0)[0]\n",
    "    if len(cutoff):\n",
    "        n_pairs[ml_idx, mh_idx, cutoff[0] + 1:] = 0\n",
    "        cutoff_calc = 2 * n_fractals - 2 - ml_idx - mh_idx + int(ml_idx + mh_idx >= n_fractals - 1)\n",
    "        \n",
    "# remove max and min corners due to lower variance threshold\n",
    "n_pairs[0, :] = 0\n",
    "n_pairs[:, 0] = 0\n",
    "\n",
    "# remove setups with not enough unique gamble pairs\n",
    "n_pairs[n_pairs < min_unique_gambles] = 0\n",
    "\n",
    "print(\"Gamble pair space subset: \", np.sum(n_pairs != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed07f0e-79f3-495b-afbb-514ba1b94cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = join(\"data\", \"v2\", f\"simulation_{agent_name(eta_dynamic)}\")\n",
    "Path(path_output).mkdir(exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0841f5-2506-4146-8842-101e67a12b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = len(agents)\n",
    "\n",
    "shape_common = (n_mag_thrs, n_mag_thrs, n_dmag_thrs, n_c)\n",
    "shape_pair = (math.comb(n_agents, 2), ) + shape_common\n",
    "shape_single = (n_agents, ) + shape_common\n",
    "\n",
    "# Statistics\n",
    "d_p = np.zeros(shape_pair)\n",
    "d_y = np.zeros(shape_pair)\n",
    "p_bank = np.zeros(shape_single)\n",
    "p_rich = np.zeros(shape_single)\n",
    "avg_len = np.zeros(shape_single)\n",
    "n_gamble_pairs = np.zeros(shape_common)\n",
    "\n",
    "c_range = np.linspace(c_min, c_max, n_c)\n",
    "for c_idx, c in tqdm(list(enumerate(c_range))):\n",
    "    \n",
    "    mag_thrs = create_mag_thrs(c, n_fractals)\n",
    "    dmag_thrs = create_dmag_thrs(c, n_fractals)\n",
    "    \n",
    "    for ml_idx, mh_idx in product(range(n_mag_thrs), repeat=2):\n",
    "        for md_idx in range(n_dmag_thrs):\n",
    "                        \n",
    "            if n_pairs[ml_idx, mh_idx, md_idx] == 0:\n",
    "                # Ignore excluded parameter values\n",
    "                continue\n",
    "        \n",
    "            # Translate bound indices into average growth rates\n",
    "            ml_bound = mag_thrs[ml_idx]\n",
    "            mh_bound = mag_thrs[-1 - mh_idx]\n",
    "            md_bound = dmag_thrs[md_idx]\n",
    "\n",
    "            # Create & filter gambles \n",
    "            gambles = create_gambles(c, n_fractals=n_fractals)\n",
    "            gambles = [\n",
    "                g for g in gambles \n",
    "                if np.mean(g) > ml_bound\n",
    "                and np.mean(g) < mh_bound\n",
    "                and not is_g_deterministic(g)\n",
    "            ]\n",
    "\n",
    "            # Create & filter gamble pairs\n",
    "            gamble_pairs = create_gamble_pairs(gambles)\n",
    "            gamble_pairs = [\n",
    "                gp for gp in gamble_pairs \n",
    "                if np.abs(np.mean(gp[0]) - np.mean(gp[1])) < md_bound\n",
    "                if not is_nobrainer(gp)\n",
    "            ]\n",
    "\n",
    "            # Create experiment and randomized trial order\n",
    "            experiment = create_experiment(gamble_pairs)\n",
    "            trial_order = create_trial_order(\n",
    "                n_simulations, \n",
    "                experiment.shape[-1], \n",
    "                n_trials\n",
    "            )\n",
    "\n",
    "            x, y, p = {}, {}, {}\n",
    "            for agent in agents:\n",
    "\n",
    "                # Estimate precision\n",
    "                beta = calculate_beta(\n",
    "                    eta_dynamic=eta_dynamic,\n",
    "                    eta_agent=agent,\n",
    "                    x_0=x_0,\n",
    "                    x_limit=x_limit,\n",
    "                    p_threshold=p_threshold,\n",
    "                    c=c,\n",
    "                )\n",
    "\n",
    "                x[agent], p[agent], y[agent] = run_simulation(\n",
    "                    experiment=experiment,\n",
    "                    trial_order=trial_order,\n",
    "                    eta_dynamic=eta_dynamic,\n",
    "                    eta_agent=agent,\n",
    "                    x_0=x_0,\n",
    "                    x_limit=x_limit,\n",
    "                    beta=beta,\n",
    "                    wealth_dependency=wealth_dependency\n",
    "                )\n",
    "\n",
    "            # Store statistics\n",
    "            for i, (a1, a2) in enumerate(combinations(agents, 2)):\n",
    "                d_p[i, ml_idx, mh_idx, md_idx, c_idx] = disagreement(p[a1], p[a2])        \n",
    "                d_y[i, ml_idx, mh_idx, md_idx, c_idx] = disagreement(y[a1], y[a2])\n",
    "            for i, a in enumerate(agents):\n",
    "                p_bank[i, ml_idx, mh_idx, md_idx, c_idx] = bankruptcy_chance(x[a])\n",
    "                p_rich[i, ml_idx, mh_idx, md_idx, c_idx] = richness_chance(x[a], x_limit)\n",
    "                avg_len[i, ml_idx, mh_idx, md_idx, c_idx] = experiment_duration(x[a], x_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc34db-1bbb-43cf-9919-c45df7318f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store main data\n",
    "np.save(join(path_output, \"d_p.npy\"), d_p)\n",
    "np.save(join(path_output, \"d_y.npy\"), d_y)\n",
    "np.save(join(path_output, \"p_rich.npy\"), p_rich)\n",
    "np.save(join(path_output, \"p_bank.npy\"), p_bank)\n",
    "np.save(join(path_output, \"avg_len.npy\"), avg_len)\n",
    "np.save(join(path_output, \"n_pairs.npy\"), n_pairs)\n",
    "\n",
    "# Create and store metadata\n",
    "dimensions = {\n",
    "    0: list(combinations(agents, 2)),\n",
    "    1: list(create_mag_thrs(1, n_fractals)[:n_mag_thrs]),\n",
    "    2: list(create_mag_thrs(1, n_fractals)[-n_mag_thrs:]),\n",
    "    3: list(create_dmag_thrs(1, n_fractals)),\n",
    "    4: list(c_range)\n",
    "}\n",
    "\n",
    "meta = {\n",
    "    \"x_0\": x_0,\n",
    "    \"x_limit\": x_limit,\n",
    "    \"n_fractals\": n_fractals,\n",
    "    \"n_trials\": n_trials,\n",
    "    \"p_threshold\": p_threshold,\n",
    "    \"agents\": agents,\n",
    "    \"eta_dynamic\": eta_dynamic,\n",
    "    \"c_min\": c_min,\n",
    "    \"c_max\": c_max,\n",
    "    \"n_c\": n_c,\n",
    "    \"min_unique_gambles\": min_unique_gambles,\n",
    "    \"max_mag_n\": max_mag_n,\n",
    "    \"n_simulations\": n_simulations,\n",
    "    \"wealth_dependency\": wealth_dependency,\n",
    "    \"dimensions\": dimensions\n",
    "}\n",
    "\n",
    "with open(join(path_output, \"metadata.json\"), \"w\") as f:\n",
    "    f.writelines(json.dumps(meta, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
